[2024-06-16T00:00:20.918+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-16T00:00:21.011+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [queued]>
[2024-06-16T00:00:21.047+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [queued]>
[2024-06-16T00:00:21.050+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 6
[2024-06-16T00:00:21.086+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): visualization> on 2024-06-15 00:00:00+00:00
[2024-06-16T00:00:21.096+0000] {standard_task_runner.py:63} INFO - Started process 3385 to run task
[2024-06-16T00:00:21.102+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Air_pollution_data_pipeline', 'visualization', 'scheduled__2024-06-15T00:00:00+00:00', '--job-id', '71', '--raw', '--subdir', 'DAGS_FOLDER/main.py', '--cfg-path', '/tmp/tmp0h1nv9b1']
[2024-06-16T00:00:21.114+0000] {standard_task_runner.py:91} INFO - Job 71: Subtask visualization
[2024-06-16T00:00:21.456+0000] {task_command.py:426} INFO - Running <TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [running]> on host 6e26965f02f1
[2024-06-16T00:00:22.644+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='khalid' AIRFLOW_CTX_DAG_ID='Air_pollution_data_pipeline' AIRFLOW_CTX_TASK_ID='visualization' AIRFLOW_CTX_EXECUTION_DATE='2024-06-15T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-15T00:00:00+00:00'
[2024-06-16T00:00:22.662+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-16T00:00:22.665+0000] {visualization.py:12} INFO - starting data visualization
[2024-06-16T00:00:22.688+0000] {logging_mixin.py:188} WARNING - /opt/***/dags/statistical_analysis/visualization.py:15 FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.
[2024-06-16T00:00:23.130+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-16T00:00:23.131+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-16T00:00:23.148+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=Air_pollution_data_pipeline, task_id=visualization, run_id=scheduled__2024-06-15T00:00:00+00:00, execution_date=20240615T000000, start_date=20240616T000021, end_date=20240616T000023
[2024-06-16T00:00:23.200+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-16T00:00:23.239+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-16T00:00:23.242+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-16T15:51:45.573+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-16T15:51:45.956+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [queued]>
[2024-06-16T15:51:46.021+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [queued]>
[2024-06-16T15:51:46.023+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 6
[2024-06-16T15:51:46.121+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): visualization> on 2024-06-15 00:00:00+00:00
[2024-06-16T15:51:46.158+0000] {standard_task_runner.py:63} INFO - Started process 306 to run task
[2024-06-16T15:51:46.276+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Air_pollution_data_pipeline', 'visualization', 'scheduled__2024-06-15T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/main.py', '--cfg-path', '/tmp/tmprqblq0sj']
[2024-06-16T15:51:46.327+0000] {standard_task_runner.py:91} INFO - Job 15: Subtask visualization
[2024-06-16T15:51:46.728+0000] {task_command.py:426} INFO - Running <TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [running]> on host 333385971b19
[2024-06-16T15:51:47.169+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='khalid' AIRFLOW_CTX_DAG_ID='Air_pollution_data_pipeline' AIRFLOW_CTX_TASK_ID='visualization' AIRFLOW_CTX_EXECUTION_DATE='2024-06-15T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-15T00:00:00+00:00'
[2024-06-16T15:51:47.172+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-16T15:51:47.173+0000] {visualization.py:12} INFO - starting data visualization
[2024-06-16T15:51:47.178+0000] {visualization.py:31} ERROR - error visualizing data
Traceback (most recent call last):
  File "/opt/airflow/dags/statistical_analysis/visualization.py", line 15, in visualization
    val_data = pd.read_json(val_data)
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/io/json/_json.py", line 791, in read_json
    json_reader = JsonReader(
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/io/json/_json.py", line 904, in __init__
    data = self._get_data_from_filepath(filepath_or_buffer)
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/io/json/_json.py", line 944, in _get_data_from_filepath
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/io/common.py", line 728, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/io/common.py", line 472, in _get_filepath_or_buffer
    raise ValueError(msg)
ValueError: Invalid file path or buffer object type: <class 'NoneType'>
[2024-06-16T15:51:47.183+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-16T15:51:47.184+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-16T15:51:47.205+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=Air_pollution_data_pipeline, task_id=visualization, run_id=scheduled__2024-06-15T00:00:00+00:00, execution_date=20240615T000000, start_date=20240616T155145, end_date=20240616T155147
[2024-06-16T15:51:47.294+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-16T15:51:47.373+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-16T15:51:47.403+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-16T16:48:27.578+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-16T16:48:27.919+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [queued]>
[2024-06-16T16:48:27.959+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [queued]>
[2024-06-16T16:48:27.960+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 6
[2024-06-16T16:48:28.035+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): visualization> on 2024-06-15 00:00:00+00:00
[2024-06-16T16:48:28.915+0000] {standard_task_runner.py:63} INFO - Started process 3624 to run task
[2024-06-16T16:48:29.029+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Air_pollution_data_pipeline', 'visualization', 'scheduled__2024-06-15T00:00:00+00:00', '--job-id', '404', '--raw', '--subdir', 'DAGS_FOLDER/main.py', '--cfg-path', '/tmp/tmpimrvvboi']
[2024-06-16T16:48:29.176+0000] {standard_task_runner.py:91} INFO - Job 404: Subtask visualization
[2024-06-16T16:48:30.215+0000] {task_command.py:426} INFO - Running <TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [running]> on host 333385971b19
[2024-06-16T16:48:36.606+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='khalid' AIRFLOW_CTX_DAG_ID='Air_pollution_data_pipeline' AIRFLOW_CTX_TASK_ID='visualization' AIRFLOW_CTX_EXECUTION_DATE='2024-06-15T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-15T00:00:00+00:00'
[2024-06-16T16:48:36.639+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-16T16:48:36.663+0000] {visualization.py:12} INFO - starting data visualization
[2024-06-16T16:48:36.886+0000] {logging_mixin.py:188} WARNING - /opt/***/dags/statistical_analysis/visualization.py:15 FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.
[2024-06-16T16:48:46.846+0000] {visualization.py:31} ERROR - error visualizing data
Traceback (most recent call last):
  File "/opt/airflow/dags/statistical_analysis/visualization.py", line 17, in visualization
    data_to_plot = val_data.drop(["Entity", "Code"], axis = 1)
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/frame.py", line 5581, in drop
    return super().drop(
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/generic.py", line 4788, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/generic.py", line 4830, in _drop_axis
    new_axis = axis.drop(labels, errors=errors)
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 7070, in drop
    raise KeyError(f"{labels[mask].tolist()} not found in axis")
KeyError: "['Code'] not found in axis"
[2024-06-16T16:48:46.984+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-16T16:48:46.985+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-16T16:48:47.120+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=Air_pollution_data_pipeline, task_id=visualization, run_id=scheduled__2024-06-15T00:00:00+00:00, execution_date=20240615T000000, start_date=20240616T164827, end_date=20240616T164847
[2024-06-16T16:48:47.435+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-16T16:48:47.525+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-17T03:59:56.205+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T03:59:56.313+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [queued]>
[2024-06-17T03:59:56.339+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [queued]>
[2024-06-17T03:59:56.340+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 6
[2024-06-17T03:59:56.373+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): visualization> on 2024-06-15 00:00:00+00:00
[2024-06-17T03:59:56.384+0000] {standard_task_runner.py:63} INFO - Started process 302 to run task
[2024-06-17T03:59:56.393+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Air_pollution_data_pipeline', 'visualization', 'scheduled__2024-06-15T00:00:00+00:00', '--job-id', '23', '--raw', '--subdir', 'DAGS_FOLDER/main.py', '--cfg-path', '/tmp/tmp103a054b']
[2024-06-17T03:59:56.401+0000] {standard_task_runner.py:91} INFO - Job 23: Subtask visualization
[2024-06-17T03:59:56.525+0000] {task_command.py:426} INFO - Running <TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [running]> on host fa4d239664b0
[2024-06-17T03:59:56.770+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='khalid' AIRFLOW_CTX_DAG_ID='Air_pollution_data_pipeline' AIRFLOW_CTX_TASK_ID='visualization' AIRFLOW_CTX_EXECUTION_DATE='2024-06-15T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-15T00:00:00+00:00'
[2024-06-17T03:59:56.772+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T03:59:56.774+0000] {visualization.py:12} INFO - starting data visualization
[2024-06-17T03:59:56.777+0000] {visualization.py:31} ERROR - error visualizing data
Traceback (most recent call last):
  File "/opt/airflow/dags/statistical_analysis/visualization.py", line 15, in visualization
    val_data = pd.read_json(val_data)
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/io/json/_json.py", line 791, in read_json
    json_reader = JsonReader(
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/io/json/_json.py", line 904, in __init__
    data = self._get_data_from_filepath(filepath_or_buffer)
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/io/json/_json.py", line 944, in _get_data_from_filepath
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/io/common.py", line 728, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/io/common.py", line 472, in _get_filepath_or_buffer
    raise ValueError(msg)
ValueError: Invalid file path or buffer object type: <class 'NoneType'>
[2024-06-17T03:59:56.783+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-17T03:59:56.785+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T03:59:56.809+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=Air_pollution_data_pipeline, task_id=visualization, run_id=scheduled__2024-06-15T00:00:00+00:00, execution_date=20240615T000000, start_date=20240617T035956, end_date=20240617T035956
[2024-06-17T03:59:56.887+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-17T03:59:56.910+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T10:47:02.207+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T10:47:02.668+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [queued]>
[2024-06-18T10:47:02.706+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [queued]>
[2024-06-18T10:47:02.715+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 6
[2024-06-18T10:47:03.530+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): visualization> on 2024-06-15 00:00:00+00:00
[2024-06-18T10:47:03.617+0000] {standard_task_runner.py:63} INFO - Started process 416 to run task
[2024-06-18T10:47:03.696+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Air_pollution_data_pipeline', 'visualization', 'scheduled__2024-06-15T00:00:00+00:00', '--job-id', '20', '--raw', '--subdir', 'DAGS_FOLDER/main.py', '--cfg-path', '/tmp/tmp0eyqapao']
[2024-06-18T10:47:03.729+0000] {standard_task_runner.py:91} INFO - Job 20: Subtask visualization
[2024-06-18T10:47:07.835+0000] {task_command.py:426} INFO - Running <TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [running]> on host 14ae0373fd5a
[2024-06-18T10:47:20.125+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='khalid' AIRFLOW_CTX_DAG_ID='Air_pollution_data_pipeline' AIRFLOW_CTX_TASK_ID='visualization' AIRFLOW_CTX_EXECUTION_DATE='2024-06-15T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-15T00:00:00+00:00'
[2024-06-18T10:47:20.147+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T10:47:20.152+0000] {visualization.py:26} INFO - starting data visualization
[2024-06-18T10:47:20.323+0000] {logging_mixin.py:188} WARNING - /opt/***/dags/statistical_analysis/visualization.py:29 FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.
[2024-06-18T11:50:45.377+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T11:50:45.768+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [queued]>
[2024-06-18T11:50:45.812+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [queued]>
[2024-06-18T11:50:45.814+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 6
[2024-06-18T11:50:45.880+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): visualization> on 2024-06-15 00:00:00+00:00
[2024-06-18T11:50:45.964+0000] {standard_task_runner.py:63} INFO - Started process 406 to run task
[2024-06-18T11:50:46.234+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Air_pollution_data_pipeline', 'visualization', 'scheduled__2024-06-15T00:00:00+00:00', '--job-id', '19', '--raw', '--subdir', 'DAGS_FOLDER/main.py', '--cfg-path', '/tmp/tmphj06wayj']
[2024-06-18T11:50:46.288+0000] {standard_task_runner.py:91} INFO - Job 19: Subtask visualization
[2024-06-18T11:50:47.053+0000] {task_command.py:426} INFO - Running <TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [running]> on host dc6d39ed067c
[2024-06-18T11:50:54.112+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='khalid' AIRFLOW_CTX_DAG_ID='Air_pollution_data_pipeline' AIRFLOW_CTX_TASK_ID='visualization' AIRFLOW_CTX_EXECUTION_DATE='2024-06-15T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-15T00:00:00+00:00'
[2024-06-18T11:50:54.143+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T11:50:54.196+0000] {visualization.py:26} INFO - starting data visualization
[2024-06-18T11:50:54.819+0000] {logging_mixin.py:188} WARNING - /opt/***/dags/statistical_analysis/visualization.py:29 FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.
[2024-06-18T11:51:05.559+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-18T11:51:05.589+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T11:51:05.767+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=Air_pollution_data_pipeline, task_id=visualization, run_id=scheduled__2024-06-15T00:00:00+00:00, execution_date=20240615T000000, start_date=20240618T115045, end_date=20240618T115105
[2024-06-18T11:51:06.602+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T11:51:06.764+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-18T11:51:06.783+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T20:06:04.738+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T20:06:06.217+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [queued]>
[2024-06-19T20:06:06.375+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [queued]>
[2024-06-19T20:06:06.377+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 6
[2024-06-19T20:06:07.058+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): visualization> on 2024-06-15 00:00:00+00:00
[2024-06-19T20:06:07.172+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Air_pollution_data_pipeline', 'visualization', 'scheduled__2024-06-15T00:00:00+00:00', '--job-id', '28', '--raw', '--subdir', 'DAGS_FOLDER/main.py', '--cfg-path', '/tmp/tmp5rtn8dzf']
[2024-06-19T20:06:07.239+0000] {standard_task_runner.py:91} INFO - Job 28: Subtask visualization
[2024-06-19T20:06:07.230+0000] {standard_task_runner.py:63} INFO - Started process 346 to run task
[2024-06-19T20:06:09.306+0000] {task_command.py:426} INFO - Running <TaskInstance: Air_pollution_data_pipeline.visualization scheduled__2024-06-15T00:00:00+00:00 [running]> on host 0bfb368fa6be
[2024-06-19T20:06:13.040+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='khalid' AIRFLOW_CTX_DAG_ID='Air_pollution_data_pipeline' AIRFLOW_CTX_TASK_ID='visualization' AIRFLOW_CTX_EXECUTION_DATE='2024-06-15T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-15T00:00:00+00:00'
[2024-06-19T20:06:13.047+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T20:06:13.050+0000] {visualization.py:26} INFO - starting data visualization
[2024-06-19T20:06:13.158+0000] {logging_mixin.py:188} WARNING - /opt/***/dags/statistical_analysis/visualization.py:29 FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.
[2024-06-19T20:06:16.037+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T20:06:16.039+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T20:06:16.084+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=Air_pollution_data_pipeline, task_id=visualization, run_id=scheduled__2024-06-15T00:00:00+00:00, execution_date=20240615T000000, start_date=20240619T200606, end_date=20240619T200616
[2024-06-19T20:06:16.199+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T20:06:16.335+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T20:06:16.392+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
