[2024-06-19T00:00:37.588+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T00:00:37.649+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.insert_into_db_table__2 scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:00:37.678+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.insert_into_db_table__2 scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:00:37.679+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 6
[2024-06-19T00:00:37.709+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): insert_into_db_table__2> on 2024-06-18 00:00:00+00:00
[2024-06-19T00:00:37.728+0000] {standard_task_runner.py:63} INFO - Started process 15663 to run task
[2024-06-19T00:00:37.738+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Air_pollution_data_pipeline', 'insert_into_db_table__2', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '214', '--raw', '--subdir', 'DAGS_FOLDER/main.py', '--cfg-path', '/tmp/tmpcb059xp3']
[2024-06-19T00:00:37.743+0000] {standard_task_runner.py:91} INFO - Job 214: Subtask insert_into_db_table__2
[2024-06-19T00:00:37.927+0000] {task_command.py:426} INFO - Running <TaskInstance: Air_pollution_data_pipeline.insert_into_db_table__2 scheduled__2024-06-18T00:00:00+00:00 [running]> on host dc6d39ed067c
[2024-06-19T00:00:38.128+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='khalid' AIRFLOW_CTX_DAG_ID='Air_pollution_data_pipeline' AIRFLOW_CTX_TASK_ID='insert_into_db_table__2' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T00:00:38.129+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T00:00:38.141+0000] {logging_mixin.py:188} WARNING - /opt/***/dags/database/populate_db.py:29 FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.
[2024-06-19T00:00:38.163+0000] {populate_db.py:48} INFO - Inserting data into table
[2024-06-19T00:00:38.165+0000] {baseoperator.py:400} WARNING - SQLExecuteQueryOperator.execute cannot be called outside TaskInstance!
[2024-06-19T00:00:38.166+0000] {sql.py:276} INFO - Executing: 
            INSERT INTO emission_summary_stats (Year, Nitrogen_oxide_NOx, Sulphur_dioxide_SO_emissions, Carbon_monoxide_CO_emissions, Organic_carbon_OC_emissions, Non_methane_volatile_organic_compounds_NMVOC_emissions, Black_carbon_BC_emissions, Ammonia_NH_emissions, summary_stats)
            VALUES (45717.0, 45717.0, 45717.0, 45717.0, 45717.0, 45717.0, 45717.0, 45717.0, 'count'),(1911.2044097382, 285628.6596008223, 427054.8537001305, 2578258.2101170714, 69388.0866882038, 463736.5903423727, 25006.0574584827, 185872.8243646251, 'mean'),(67.6401001473, 3524839.723219105, 4525329.3834697595, 23246546.971131656, 553392.1190267598, 4726834.392684209, 223952.597645769, 1898858.498607165, 'std'),(1750.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 'min'),(1854.0, 137.85605, 58.138058, 12165.899, 519.6276, 2124.2761, 131.87717, 1207.5621, '25%'),(1914.0, 1403.7751, 731.89014, 93669.86, 3824.931, 14941.013, 954.0942, 8457.144, '50%'),(1970.0, 22905.088, 21654.107, 470762.56, 17826.033, 90858.164, 4994.4277, 39316.773, '75%'),(2022.0, 109243090.0, 134596620.0, 599913340.0, 13618318.0, 135481700.0, 6141969.0, 63947644.0, 'max')
        
[2024-06-19T00:00:38.181+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-19T00:00:38.204+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-19T00:00:38.212+0000] {sql.py:487} INFO - Running statement: 
            INSERT INTO emission_summary_stats (Year, Nitrogen_oxide_NOx, Sulphur_dioxide_SO_emissions, Carbon_monoxide_CO_emissions, Organic_carbon_OC_emissions, Non_methane_volatile_organic_compounds_NMVOC_emissions, Black_carbon_BC_emissions, Ammonia_NH_emissions, summary_stats)
            VALUES (45717.0, 45717.0, 45717.0, 45717.0, 45717.0, 45717.0, 45717.0, 45717.0, 'count'),(1911.2044097382, 285628.6596008223, 427054.8537001305, 2578258.2101170714, 69388.0866882038, 463736.5903423727, 25006.0574584827, 185872.8243646251, 'mean'),(67.6401001473, 3524839.723219105, 4525329.3834697595, 23246546.971131656, 553392.1190267598, 4726834.392684209, 223952.597645769, 1898858.498607165, 'std'),(1750.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 'min'),(1854.0, 137.85605, 58.138058, 12165.899, 519.6276, 2124.2761, 131.87717, 1207.5621, '25%'),(1914.0, 1403.7751, 731.89014, 93669.86, 3824.931, 14941.013, 954.0942, 8457.144, '50%'),(1970.0, 22905.088, 21654.107, 470762.56, 17826.033, 90858.164, 4994.4277, 39316.773, '75%'),(2022.0, 109243090.0, 134596620.0, 599913340.0, 13618318.0, 135481700.0, 6141969.0, 63947644.0, 'max')
        , parameters: None
[2024-06-19T00:00:38.215+0000] {populate_db.py:59} ERROR - Error inserting data into table
Traceback (most recent call last):
  File "/opt/airflow/dags/database/populate_db.py", line 54, in insert_into_db_table
    insert_data_task.execute(context=None)  # Execute the task
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/common/sql/operators/sql.py", line 282, in execute
    output = hook.run(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/common/sql/hooks/sql.py", line 435, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/common/sql/hooks/sql.py", line 492, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UndefinedColumn: column "nitrogen_oxide_nox" of relation "emission_summary_stats" does not exist
LINE 2: ...        INSERT INTO emission_summary_stats (Year, Nitrogen_o...
                                                             ^

[2024-06-19T00:00:38.219+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T00:00:38.222+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/database/populate_db.py", line 54, in insert_into_db_table
    insert_data_task.execute(context=None)  # Execute the task
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/common/sql/operators/sql.py", line 282, in execute
    output = hook.run(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/common/sql/hooks/sql.py", line 435, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/common/sql/hooks/sql.py", line 492, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UndefinedColumn: column "nitrogen_oxide_nox" of relation "emission_summary_stats" does not exist
LINE 2: ...        INSERT INTO emission_summary_stats (Year, Nitrogen_o...
                                                             ^

[2024-06-19T00:00:38.245+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=Air_pollution_data_pipeline, task_id=insert_into_db_table__2, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T000037, end_date=20240619T000038
[2024-06-19T00:00:38.313+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 214 for task insert_into_db_table__2 (column "nitrogen_oxide_nox" of relation "emission_summary_stats" does not exist
LINE 2: ...        INSERT INTO emission_summary_stats (Year, Nitrogen_o...
                                                             ^
; 15663)
[2024-06-19T00:00:38.393+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-19T00:00:38.485+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T00:00:38.492+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T20:14:05.865+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T20:14:06.276+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.insert_into_db_table__2 scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T20:14:06.426+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Air_pollution_data_pipeline.insert_into_db_table__2 scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T20:14:06.428+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 6
[2024-06-19T20:14:06.523+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): insert_into_db_table__2> on 2024-06-18 00:00:00+00:00
[2024-06-19T20:14:06.541+0000] {standard_task_runner.py:63} INFO - Started process 730 to run task
[2024-06-19T20:14:06.635+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Air_pollution_data_pipeline', 'insert_into_db_table__2', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '77', '--raw', '--subdir', 'DAGS_FOLDER/main.py', '--cfg-path', '/tmp/tmpwryobd4g']
[2024-06-19T20:14:06.701+0000] {standard_task_runner.py:91} INFO - Job 77: Subtask insert_into_db_table__2
[2024-06-19T20:14:07.024+0000] {task_command.py:426} INFO - Running <TaskInstance: Air_pollution_data_pipeline.insert_into_db_table__2 scheduled__2024-06-18T00:00:00+00:00 [running]> on host 0bfb368fa6be
[2024-06-19T20:14:07.670+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='khalid' AIRFLOW_CTX_DAG_ID='Air_pollution_data_pipeline' AIRFLOW_CTX_TASK_ID='insert_into_db_table__2' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T20:14:07.674+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T20:14:07.726+0000] {logging_mixin.py:188} WARNING - /opt/***/dags/database/populate_db.py:29 FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.
[2024-06-19T20:14:07.833+0000] {populate_db.py:48} INFO - Inserting data into table
[2024-06-19T20:14:07.847+0000] {baseoperator.py:400} WARNING - SQLExecuteQueryOperator.execute cannot be called outside TaskInstance!
[2024-06-19T20:14:07.848+0000] {sql.py:276} INFO - Executing: 
            INSERT INTO emission_summary_stats (Year, Nitrogen_oxide_NOx, Sulphur_dioxide_SO_emissions, Carbon_monoxide_CO_emissions, Organic_carbon_OC_emissions, Non_methane_volatile_organic_compounds_NMVOC_emissions, Black_carbon_BC_emissions, Ammonia_NH_emissions, summary_stats)
            VALUES (45717.0, 45717.0, 45717.0, 45717.0, 45717.0, 45717.0, 45717.0, 45717.0, 'count'),(1911.2044097382, 285628.6596008223, 427054.8537001305, 2578258.2101170714, 69388.0866882038, 463736.5903423727, 25006.0574584827, 185872.8243646251, 'mean'),(67.6401001473, 3524839.723219105, 4525329.3834697595, 23246546.971131656, 553392.1190267598, 4726834.392684209, 223952.597645769, 1898858.498607165, 'std'),(1750.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 'min'),(1854.0, 137.85605, 58.138058, 12165.899, 519.6276, 2124.2761, 131.87717, 1207.5621, '25%'),(1914.0, 1403.7751, 731.89014, 93669.86, 3824.931, 14941.013, 954.0942, 8457.144, '50%'),(1970.0, 22905.088, 21654.107, 470762.56, 17826.033, 90858.164, 4994.4277, 39316.773, '75%'),(2022.0, 109243090.0, 134596620.0, 599913340.0, 13618318.0, 135481700.0, 6141969.0, 63947644.0, 'max')
        
[2024-06-19T20:14:07.923+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-19T20:14:08.152+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-19T20:14:08.312+0000] {sql.py:487} INFO - Running statement: 
            INSERT INTO emission_summary_stats (Year, Nitrogen_oxide_NOx, Sulphur_dioxide_SO_emissions, Carbon_monoxide_CO_emissions, Organic_carbon_OC_emissions, Non_methane_volatile_organic_compounds_NMVOC_emissions, Black_carbon_BC_emissions, Ammonia_NH_emissions, summary_stats)
            VALUES (45717.0, 45717.0, 45717.0, 45717.0, 45717.0, 45717.0, 45717.0, 45717.0, 'count'),(1911.2044097382, 285628.6596008223, 427054.8537001305, 2578258.2101170714, 69388.0866882038, 463736.5903423727, 25006.0574584827, 185872.8243646251, 'mean'),(67.6401001473, 3524839.723219105, 4525329.3834697595, 23246546.971131656, 553392.1190267598, 4726834.392684209, 223952.597645769, 1898858.498607165, 'std'),(1750.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 'min'),(1854.0, 137.85605, 58.138058, 12165.899, 519.6276, 2124.2761, 131.87717, 1207.5621, '25%'),(1914.0, 1403.7751, 731.89014, 93669.86, 3824.931, 14941.013, 954.0942, 8457.144, '50%'),(1970.0, 22905.088, 21654.107, 470762.56, 17826.033, 90858.164, 4994.4277, 39316.773, '75%'),(2022.0, 109243090.0, 134596620.0, 599913340.0, 13618318.0, 135481700.0, 6141969.0, 63947644.0, 'max')
        , parameters: None
[2024-06-19T20:14:08.342+0000] {sql.py:496} INFO - Rows affected: 8
[2024-06-19T20:14:08.376+0000] {populate_db.py:56} INFO - successfully insert data into table
[2024-06-19T20:14:08.394+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-19T20:14:08.518+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T20:14:08.887+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=Air_pollution_data_pipeline, task_id=insert_into_db_table__2, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T201406, end_date=20240619T201408
[2024-06-19T20:14:09.096+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T20:14:09.248+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T20:14:09.292+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
